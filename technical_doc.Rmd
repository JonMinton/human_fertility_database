---
title: Merging, exploring, and batch processing data from the Human Fertility Database
  and Human Mortality Database
author: "Dr Jon Minton"
date: "Sunday, February 22, 2015"
output: word_document
---
#Introduction

As well as picking and choosing particular countries and variables to download from the Human Fertality
Database (HFD) and the Human Mortality Database (HMD), it is also possible to initiate a bulk 
download of all data from either database. In both cases, the user is presented with a compressed 
file in .zip format, containing a number of separate variables in a large number of separate files.
In the case of the Human Mortality Database, the same variable is contained in separate files
in separate directories for each of the countries for which the variable have been collected. 
Although, when interested in a single country's records, it can be relatively straightforward to 
identify which file, from which directory, the appropriate data should be loaded from, 
some analyses would require accessing a large number of files, and so the amount of effort 
required to manage the data in these cases would be much increased. For example, if a researcher 
wants to combine population and death counts from a number of countries, and further form this
to see how a variable differs in one country compared with a number of others, then the number of 
separate files that would need to be accessed could be very large. 

If, instead, relevant data from a number of separate countries, and for a number of separate 
variables of interest, were available, in a consistent format, within a single file, then the amount 
of effort required to perform such comparative analyses can be much reduced. 

The first part of this technical report will describe how to use two functions that I have developed, in R, in order to automatically merge a large number of files from the HFD, and HMD respectively, into just two datafiles, which can be then saved as plain text files, ready to use for further analyses. The second part of this technical report presents a motivating example, showing the benefits of having such data in a smaller number of files, by showing how the process of producing shaded contour plots (SCPs) for each of the countries and variables included can then be automated, meaning that potentially hundreds of different analyses can be produced and updated very quickly. 

Both the functions for data gathering presented in the first half of the technical report, and the functions which generate images as presented in the second half of the technical report, make extensive use of the 'plyr' package, and the associated 'split-apply-combine' paradigm. Readers are encouraged to learn more about the plyr package, and the related dplyr package, and to explore the contents of the functions used here, in order to understand how they work, and how the functions and approach described here can be applied to a much wider range of data management and analyses tasks in demographic analyses. However even if the functions are thought of as 'black boxes' and their contents are not explored, it is hoped that the outputs they produce will be valuable to researchers in cutting down the amount of time they need to spend on data management tasks rather than substantive analyses. 

# Preparation

## Tidy Data Principles

Hadley Wickham defines a dataset as 'tidy' if:
1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table. 

[REF: p4 of http://vita.had.co.nz/papers/tidy-data.pdf]

Each row within a 'tidy data' format table contains two types of variable:

1. 'Where' variables, defining the 'location' of the observation; and 
2. 'What' Variables, defining the value measured at the 'location'.

In the case of the demographic data of interest in this exercise, 'location' variables include:

1. Age;
2. Year;
3. Country;
4. Sex (for the HMD).

Each row therefore begins with the three (HFD) or four (HMD) location variables, followed by a number of observation variables for that particular location. These could include:

1. Death counts.
2. Population counts.
3. Births

With data arranged this format, it becomes easier to derive additional variables, to compare between groups, and to automate the production of outputs for each country separately. 

Note it is important that 'location' variables are compatible. In the case of demographic data, is is particularly important to ensure that the years and ages to be combined all refer to either Lexis squares, or Lexis triangles, or Lexis parallograms, and not to an inconsistent mixture of these. [REFS] Combining data in this way would be incorrect, and analogous within demography of using different coordinate reference systems within geographical information systems (GIS). 

The functions presented here will all make use of variables aggregated to Lexis squares using calender time in years. [CLARIFICATIONS] However similar functions could be written to fetch other forms of compatible data. 

##Accessing all available data from the HFD
- Go to humanfertility.org and select login from the Registration section of the column on the left of the page. 
- Once logged in, select 'Zipped Data Files' under the 'DATA' section of the column on the left of the page.
- Within the table 'Data by type', look for the link to the data type 'All types of HFD' data. Click on this link to begin the download.

The size of the HFD file is around 25Mb.  Once unzipped, this increases to around 144Mb. 


##Accessing all available data from the HMD
- Go to mortality.org and log in.
- Select 'Zipped Data Files'; scroll to the bottom of the page and click on the link in the table 'All countries for the HMD'. 

- Once logged in, select 'Zipped Data Files' under the 'DATA' section of the column on the left of the page.
- Within the table 'Data by type', look for the link to the data type 'All types of HFD' data. Click on this link to begin the download.

The size of the HMD file is around 311 Mb. Once unzipped, this increases to around 1.24 Gb. 



## Structure of hfd directory

The HFD has a relatively straightforward directory structure: within 'hfd' is a directory called 'Files', and within this directory is a directory called 'zip_w'. A total of 56 files are in this directory, and there are no additional directories.

## Structure of the hmd directory

The hmd directory has a more complex, branched structure. Once unzipped, the directory opens to 46 separate folders, each labelled with the country code of the country whose data they contain. Each of these country folders then has the same internal directory structure. As an example here is the directory structure of the first country by code, AUS:

- AUS
-- CHECKS
-- DOCS
-- InputDB
-- LexisDB
-- STATS

The STATS directory then contains 55 data files in comma-separated value (CSV) format. Within this technical document, the aim will be to extract data from the files `Deaths_1x1.txt` and `Populations.txt` from each of these subdirectories, but the methods described can be generalised to other operations.

## Data preparation

A zipped file is available alongside this technical report. This contains a subset of the data available from the HFD and HMD bulk download options, as described above. The functions described here will work using this subset of files, but in order to make best use of the functions I recommend that the full datasets are downloaded to the appropriate locations as detailed below. 

This tutorial assumes that:
- the two zipped files above have been downloaded and unzipped
- the HFD file has been unzipped into a directory called hfd
- the HMD file has been unzipped into a directory called hmd
- that both the hfd and hmd directories are within a directory called raw_data

The directory structure assumed is:

base_dir
- data
-- raw_data
--- hfd
--- hmd
-- derived_data
- scripts
- figures
-- asfr
-- population
-- log_mortality

The zipped file associated with this technical report contains a small number of files arranged in the 
structure above. In the case of the HFD it contains only the specific files that will be merged. 
In the case of the HMD example it contains only three countries/populations, rather than the more than 
thirty such countries/populations that the full HMD download contains. The functions described will work
in the same way with the reduced example datasets as with the full datasets. In the case of the HFD function it will know to ignore the additional files that are contained in the full download; and in the case of the HMD it will know to search for all subdirectories likely to contain additional country 
populations. Users are encouraged to try first with the zipped example file included with this technical report, then confirm that, when the full data are downloaded and arranged in the same format, the 
function will work as well. 

## Loading the functions 

The functions are contained in a script file, within the scripts directory above, called 'functions'. The location of the working directory within an R session can be found using 

```{r}
getwd()

```

This can be run within an R session, with base_dir as the working directory, by using the source command

```{r}
source("scripts/functions.R")

```

In order to check that the functions have been loaded correctly, we can check for all objects in the 
R workspace using 'ls()', or the functions only using 'ls.str()'. If the functions have been loaded 
correctly then either call should show the following functions to be within the R workspace

merge_lexis_square_hfd
merge_lexis_square_hmd
generate_scp_pop
generate_scp_mort
generate_scp_asfr

The two functions beginning with merge_ will merge and combine the data from the HFD and and HMD respectively, and so will be the focus of part one of this technical report. The three functions beginning with 'generate' will be used to produce SCPs using the data as arranged by the merge_ functions; they will be the focus of part two of this technical report. 

# Part one: merging and combining data from many files

## The 'merge_lexis_square_hfd' function

With the HFD data downloaded, unzipped, and in the location specificed above, we can use the merge_lexis_square_hfd function by specifying the location of the HFD directory as its first argument, named 'loc'. 

```{r}
hfd_tidy <- merge_lexis_square_hfd(loc="data/raw_data/hfd/")
```

The function takes extracts the following variables from separate HFD data: ASFR, pop....


We can look at the first few rows of the data using the head command. 

```{r}
head(hfd_tidy)
```

We can also change how the hfd_tidy data is presented to us within R by using the tbl_df() function from the 'dplyr' package. After doing this, we can see the first few observations, as well as other information about the object such as its size, just by typing the object name

```{r}
hfd_tidy <- tbl_df(hfd_tidy)
hfd_tidy
```

## The 'merge_lexis_square_hmd' function

Although it is a more complex function internally, the merge_lexis_square_hmd function can be used in exactly the same way as the merge_lexis_square_hfd function, by passing the location of the correct 
directory to the function as its first argument, called 'loc'

```{r}
hmd_tidy <- merge_lexis_square_hmd(loc="data/raw_data/hmd/")
```


